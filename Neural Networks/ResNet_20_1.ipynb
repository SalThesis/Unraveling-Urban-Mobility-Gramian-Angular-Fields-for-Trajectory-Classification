{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee5478da-27e7-4e30-a3fb-3e380084af25",
   "metadata": {},
   "source": [
    "ResNet pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a9e5e5-f5de-4b64-ad3b-14936b7ad2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import os\n",
    "\n",
    "# PyTorch dataset\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# PyTorch model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe32205-b9f6-4afc-bdb9-c744418a6b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5c9676-88b1-4020-949f-5f7dc5aaddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc126c89-4531-45bb-9b03-c3b1009b9b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f337983a-5bd0-4c6a-8604-949384be94a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform =  transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a6c838-32c8-42f2-854f-caa3933d44ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        self.images = self.load_images()\n",
    "\n",
    "    def load_images(self):\n",
    "        images = []\n",
    "        for cls in self.classes:\n",
    "            class_dir = os.path.join(self.root_dir, cls)\n",
    "            for filename in os.listdir(class_dir):\n",
    "                if filename.endswith(\".png\"):\n",
    "                    path = os.path.join(class_dir, filename)\n",
    "                    label = self.class_to_idx[cls]\n",
    "                    images.append((path, label))\n",
    "        return images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.images[idx]\n",
    "        image = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63148e76-fafb-42a2-997b-9819ba3bdc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"Data_20/train\"\n",
    "custom_dataset_train = CustomDataset(root_dir, transform = train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69686df9-1ed0-4352-808b-c83eca324bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"Data_20/val\"\n",
    "custom_dataset_val = CustomDataset(root_dir, transform = test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cb5902-e4bd-4aa1-88e8-48dd45bb8d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"Data_20/test\"\n",
    "custom_dataset_test = CustomDataset(root_dir, transform = test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4a37b3-e6a2-4022-9fab-981c79e3cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(custom_dataset_train, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0656f73c-c9bb-4667-b5ca-1ac9af30e524",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = torch.utils.data.DataLoader(custom_dataset_val, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8ffadb-139a-4db8-b18b-d4580773f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(custom_dataset_test, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03c84b1-c29f-4b78-a5fd-c16a2c1e6bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the image classes\n",
    "classes = ['Bycicle', 'Bus', 'Motorcycle', 'Pedestrian', 'Private_car', 'Taxi_or_uber']\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48249ce-1136-49fa-ad8a-dab3dcd166e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = np.transpose(img, (1, 2, 0)) \n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img = std * img + mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.imshow(img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaf7b96-48a8-46d6-89f1-fdd5532e1551",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_dataloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.numpy() \n",
    "images.shape #"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34ac3bd5-2df9-4fc8-b647-e18ad5dda9d6",
   "metadata": {},
   "source": [
    "for data, target in train_dataloader:\n",
    "    print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b65e4df-f465-4d8a-8361-dc7e1e78ed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (25, 10))\n",
    "\n",
    "for idx in np.arange(10):\n",
    "    ax = fig.add_subplot(2, int(10/2), idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(classes[labels[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610981d3-879b-4fac-af34-0105090ef50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704eef67-127b-4b66-8251-3702092fa103",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights = 'IMAGENET1K_V1')\n",
    "\n",
    "in_features = model.fc.in_features\n",
    "out_features = len(classes) \n",
    "\n",
    "model.fc = nn.Linear(in_features, out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d4ff21-2b60-4830-9dc7-9c492507d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d062b7b6-ac51-4b97-a616-6708f9105f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f468a93d-67cd-411e-b3e7-5234db112b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_f = []\n",
    "val_loss_f = []\n",
    "\n",
    "\n",
    "acc_train = []\n",
    "acc_val = []\n",
    "\n",
    "\n",
    "recall_train = []\n",
    "recall_val = []\n",
    "\n",
    "\n",
    "prec_train = []\n",
    "prec_val = []\n",
    "\n",
    "\n",
    "F1_train = []\n",
    "F1_val = []\n",
    "\n",
    "Time_list = []\n",
    "time_count = 0.0\n",
    "\n",
    "n_epochs = 50\n",
    "\n",
    "valid_loss_min = np.Inf \n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    running_correct_train = 0.0\n",
    "    running_correct_val = 0.0\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model.train()\n",
    "    for data, target in train_dataloader:\n",
    "\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        _, pred = torch.max(output, 1)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "        correct =  torch.sum(pred == target).cpu().numpy()\n",
    "        running_correct_train += correct\n",
    "\n",
    "        y_true = y_true + target.cpu().numpy().tolist()\n",
    "        y_pred = y_pred + pred.cpu().numpy().tolist()\n",
    "\n",
    "    prec_train.append(precision_recall_fscore_support(y_true, y_pred, average = 'micro')[0])\n",
    "    recall_train.append(precision_recall_fscore_support(y_true, y_pred, average = 'micro')[1])\n",
    "    F1_train.append(precision_recall_fscore_support(y_true, y_pred, average = 'micro')[2])\n",
    "\n",
    "    \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    model.eval()\n",
    "    for data, target in val_dataloader:\n",
    "\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "        output = model(data)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        \n",
    "        correct = torch.sum(pred == target).cpu().numpy()\n",
    "        running_correct_val += correct\n",
    "        \n",
    "        y_true = y_true + target.cpu().numpy().tolist()\n",
    "        y_pred = y_pred + pred.cpu().numpy().tolist()\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_count += end_time - start_time\n",
    "    Time_list.append(time_count)\n",
    "\n",
    "    prec_val.append(precision_recall_fscore_support(y_true, y_pred, average = 'micro')[0])\n",
    "    recall_val.append(precision_recall_fscore_support(y_true, y_pred, average = 'micro')[1])\n",
    "    F1_val.append(precision_recall_fscore_support(y_true, y_pred, average = 'micro')[2])\n",
    "\n",
    "\n",
    "    train_loss = train_loss/len(train_dataloader.sampler)\n",
    "    train_loss_f.append(train_loss)\n",
    "    \n",
    "    valid_loss = valid_loss/len(val_dataloader.sampler)\n",
    "    val_loss_f.append(valid_loss)\n",
    "\n",
    "    acc_train.append(running_correct_train / len(train_dataloader.sampler))\n",
    "    acc_val.append(running_correct_val / len(val_dataloader.sampler))\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_R_20_1.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d790ea-f95f-4efa-a694-e0c641580b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (4, 6))\n",
    "plt.ylim([0, 1])\n",
    "plt.xlim([0, n_epochs + 1])\n",
    "plt.plot(range(1, n_epochs + 1, 1), acc_train, label = \"Training Acc\", linewidth = 0.5)\n",
    "plt.plot(range(1, n_epochs + 1, 1), acc_val, label = \"Validation Acc\", linewidth = 0.5)\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend(loc = \"upper right\")\n",
    "plt.ylabel('Acc')\n",
    "plt.grid(color = 'lightsteelblue', linestyle = '-', linewidth = 0.12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452bf9bb-77ca-4389-a95f-6d1978583a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (4, 5))\n",
    "plt.ylim([-0.2, 2])\n",
    "plt.xlim([0, n_epochs + 1])\n",
    "plt.plot(range(1, n_epochs + 1, 1), train_loss_f, label = \"Trainig Loss\", linewidth = 0.5)\n",
    "plt.plot(range(1, n_epochs + 1, 1), val_loss_f, label = \"Validation Loss\", linewidth = 0.5)\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend(loc = \"upper right\")\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(color = 'lightsteelblue', linestyle = '-', linewidth = 0.12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118854e7-57c4-4759-b583-cd4103835014",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model_R_20_1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73d041b-e36e-4a52-9a8d-3a3293c815b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0.0\n",
    "\n",
    "class_correct = list(0. for i in range(len(classes)))\n",
    "class_total = list(0. for i in range(len(classes)))\n",
    "class_total_pred = list(0. for i in range(len(classes)))\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "for data, target in test_dataloader:\n",
    "\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "    output = model(data)\n",
    "\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    test_loss += loss.item()*data.size(0)\n",
    "\n",
    "    _, pred = torch.max(output, 1)    \n",
    "\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()).reshape(-1) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy()).reshape(-1)\n",
    "\n",
    "    y_true = y_true + target.cpu().numpy().tolist()\n",
    "    y_pred = y_pred + pred.cpu().numpy().tolist()\n",
    "    \n",
    "\n",
    "    for i in range(len(target)):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "    for i in range(len(pred)):\n",
    "        label = pred.data[i]\n",
    "        class_total_pred[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba60ab0a-c726-49a1-96c2-2b6bdee2eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698171a4-549d-4ee8-afb4-c203d08a73d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = confusion_matrix(y_true, y_pred, labels = range(len(classes)))\n",
    "disp = ConfusionMatrixDisplay(con,  display_labels = classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e05453-cc6e-43fe-afc1-fba81bd7da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.plot(xticks_rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0331eeb5-d071-46aa-abe7-8ba8db97a135",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = test_loss/len(test_dataloader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "overall_correct = sum(class_correct)\n",
    "overall_total = sum(class_total)\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * overall_correct / overall_total,\n",
    "    overall_correct, overall_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f51f67-2744-4b63-896e-8e0cc5e719d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bf18ea-bc8a-4e97-b6d0-18adde123929",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = {'epoch': range(1, n_epochs + 1, 1), 'acc_train': acc_train, 'acc_val': acc_val, 'loss_train': train_loss_f, 'loss_val': val_loss_f, 'pre_train': prec_train, 'pre_val': prec_val, 'rec_train': recall_train, 'rec_val': recall_val, 'F1_train': F1_train, 'F1_val': F1_val, 'Time': Time_list}\n",
    "df_loss_acc = pd.DataFrame(col)\n",
    "\n",
    "col = {'y_true': y_true, 'y_pred': y_pred}\n",
    "df_conf_mat = pd.DataFrame(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6be819-4082-4b56-a53c-b24f1f208766",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_acc.to_csv('metriche_R_20_1.csv', index = False)\n",
    "df_conf_mat.to_csv('confusion_matrix_R_20_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c435ef-4777-476d-be43-899ba3867897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
